{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TrB-741EYjhI"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVIR-nEeYjhK",
        "outputId": "acd283f0-413f-489d-9dbc-7406583e3f9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150, 4)\n",
            "(150,)\n"
          ]
        }
      ],
      "source": [
        "### edTest(test_data) ###\n",
        "\n",
        "# Load the iris data from sklearn datasets\n",
        "iris_data = load_iris()\n",
        "\n",
        "# Set the predictors from the Iris dataset to X\n",
        "X = iris_data.data\n",
        "\n",
        "# Set the response from the Iris dataset to X\n",
        "y = iris_data.target\n",
        "\n",
        "# Print the shape of the predictor data\n",
        "print(X.shape)\n",
        "\n",
        "# Print the shape of the response data\n",
        "print(y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7i-t2YlaLiM",
        "outputId": "48f3d721-71a0-4ce6-b7ed-ba250206f3cd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXVF2whRYjhK",
        "outputId": "fcd064d5-2e09-4168-fec3-714690a8c68a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y shape: (150, 3)\n"
          ]
        }
      ],
      "source": [
        "#from os import O_NOINHERIT\n",
        "### edTest(test_categorical) ###\n",
        "\n",
        "# Encode the response labels\n",
        "\n",
        "Y = to_categorical(y, num_classes=3)\n",
        "# Take a look at the shape of the one-hot encoded response\n",
        "print(f'Y shape: {Y.shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFpHJGRRaTRs",
        "outputId": "8a358c1e-f59c-49ea-f1bd-3d66427dd9ac"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "nFFPC8JbYjhK"
      },
      "outputs": [],
      "source": [
        "# Load and inspect the pre-trained weights and biases\n",
        "weights = np.load('weights.npy', allow_pickle=True)\n",
        "\n",
        "# Weights for hidden (1st) layer\n",
        "w1 = weights[0] \n",
        "\n",
        "# Biases for hidden (1st) layer\n",
        "b1 = weights[1]\n",
        "\n",
        "# Weights for output (2nd) layer\n",
        "w2 = weights[2]\n",
        "\n",
        "# Biases for output (2nd) layer\n",
        "b2 = weights[3] \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3516BYkYjhL",
        "outputId": "706b6819-f56f-4f15-f31a-6769ee7aecdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w1 - shape: (4, 3)\n",
            "b1 - shape: (3,)\n",
            "w2 - shape: (3, 3)\n",
            "b2 - shape: (3,)\n"
          ]
        }
      ],
      "source": [
        "# Compare their shapes to that in the NN diagram.\n",
        "for arr, name in zip([w1,b1,w2,b2], ['w1','b1','w2','b2']):\n",
        "    print(f'{name} - shape: {arr.shape}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qd2lgeWSYjhL"
      },
      "source": [
        "For the first affine transformation we need to multiply the augmented input by the first weight matrix (i.e., layer).\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "1 & X_{11} & X_{12} & X_{13} & X_{14}\\\\\n",
        "1 & X_{21} & X_{22} & X_{23} & X_{24}\\\\\n",
        "\\vdots & \\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
        "1 & X_{n1} & X_{n2} & X_{n3} & X_{n4}\\\\\n",
        "\\end{bmatrix} \\begin{bmatrix}\n",
        "b_{1}^1 & b_{2}^1 & b_{3}^1\\\\\n",
        "W_{11}^1 & W_{12}^1 & W_{13}^1\\\\\n",
        "W_{21}^1 & W_{22}^1 & W_{23}^1\\\\\n",
        "W_{31}^1 & W_{32}^1 & W_{33}^1\\\\\n",
        "W_{41}^1 & W_{42}^1 & W_{43}^1\\\\\n",
        "\\end{bmatrix} =\n",
        "\\begin{bmatrix}\n",
        "z_{11}^1 & z_{12}^1 & z_{13}^1\\\\\n",
        "z_{21}^1 & z_{22}^1 & z_{23}^1\\\\\n",
        "\\vdots & \\vdots & \\vdots \\\\\n",
        "z_{n1}^1 & z_{n2}^1 & z_{n3}^1\\\\\n",
        "\\end{bmatrix}\n",
        "= \\textbf{Z}^1\n",
        "$$ \n",
        "<span style='color:gray'>About the notation: superscript refers to the layer and subscript refers to the index in the particular matrix. So $W_{23}^1$ is the weight in the 1st layer connecting the 2nd input to 3rd hidden node. Compare this matrix representation to the slide image. Also note the bias terms and ones that have been added to 'augment' certain matrices. You could consider $b_1^1$ to be $W_{01}^1$.</span><div></div>\n",
        "<span style='color:blue'>1. Augment X with a column of ones to create `X_aug`</span><div></div><span style='color:blue'>2. Create the first layer weight matrix `W1` by vertically stacking the bias vector `b1`on top of `w1` (consult `add_ones_col` for ideas. Don't forget your `Tab` and `Shift+Tab` tricks!)</span><div></div><span style='color:blue'>3. Do the matrix multiplication to find `Z1`</span>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "hXLq56s_YjhM"
      },
      "outputs": [],
      "source": [
        "def add_ones_col(X):\n",
        "\n",
        "    '''Augment matrix with a column of ones'''\n",
        "    X_aug = np.hstack((np.ones((X.shape[0],1)), X))\n",
        "    \n",
        "    return X_aug\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "jaH-8Y1wYjhN"
      },
      "outputs": [],
      "source": [
        "### edTest(test_Z1) ###\n",
        "\n",
        "# Add a column of ones\n",
        "X_aug = add_ones_col(X)\n",
        "\n",
        "# Stack the biases to the weight matrix\n",
        "W1 = np.vstack((b1, w1))\n",
        "\n",
        "# Compute Z1 based on the equation above\n",
        "Z1 = X_aug @ W1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJ9Z88n8YjhN"
      },
      "source": [
        "Next, we use our non-linearity\n",
        "$$\n",
        "\\textit{a}_{\\text{relu}}(\\textbf{Z}^1)=\n",
        "\\begin{bmatrix}\n",
        "h_{11} & h_{12} & h_{13}\\\\\n",
        "h_{21} & h_{22} & h_{23}\\\\\n",
        "\\vdots & \\vdots & \\vdots \\\\\n",
        "h_{n1} & h_{n2} & h_{n3}\\\\\n",
        "\\end{bmatrix}= \\textbf{H}\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "<span style='color:blue'>1. Define the ReLU activation</span><div></div>\n",
        "<span style='color:blue'>2. use `plot_activation_func` to confirm implementation</span><div></div>\n",
        "<span style='color:blue'>3. Use relu on `Z1` to create `H`</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "1HmI2uwmYjhN"
      },
      "outputs": [],
      "source": [
        "def relu(z):\n",
        "    # Recall the Relu activation function from NN 1 lecture\n",
        "    \n",
        "    # Your code here\n",
        "    h = np.maximum(0,z)\n",
        "    \n",
        "    return h\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "3c5TTOJDYjhN",
        "outputId": "f51b5830-025a-4a8c-a4ad-52e79c7ded94"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Helper code to plot the activation function\n",
        "def plot_activation_func(f, name):\n",
        "    lin_x = np.linspace(-10,10,200)\n",
        "    h = f(lin_x)\n",
        "    plt.plot(lin_x, h)\n",
        "    plt.xlabel('x')\n",
        "    plt.ylabel('y')\n",
        "    plt.title(f'{name} Activation Function')\n",
        "\n",
        "plot_activation_func(relu, name='RELU')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "m1YSpEvKYjhO"
      },
      "outputs": [],
      "source": [
        "### edTest(test_relu) ###\n",
        "\n",
        "# Activate Z1 to get H\n",
        "H = relu(Z1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehMw4-MTYjhO"
      },
      "source": [
        "The next step is very similar to the first and so we've filled it in for you.\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "1 & h_{11} & h_{12} & h_{13}\\\\\n",
        "1 & h_{21} & h_{22} & h_{23}\\\\\n",
        "\\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
        "1 & h_{n1} & h_{n2} & h_{n3}\\\\\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "b_{1}^2 & b_{2}^2 & b_{3}^2\\\\\n",
        "W_{11}^2 & W_{12}^2 & W_{13}^2\\\\\n",
        "W_{21}^2 & W_{22}^2 & W_{23}^2\\\\\n",
        "W_{31}^2 & W_{32}^2 & W_{33}^2\\\\\n",
        "\\end{bmatrix}=\n",
        "\\begin{bmatrix}\n",
        "z_{11}^2 & z_{12}^2 & z_{13}^2\\\\\n",
        "z_{21}^2 & z_{22}^2 & z_{23}^2\\\\\n",
        "\\vdots & \\vdots & \\vdots \\\\\n",
        "z_{n1}^2 & z_{n2}^2 & z_{n3}^2\\\\\n",
        "\\end{bmatrix} = \\textbf{Z}^2\n",
        "$$\n",
        "\n",
        "\n",
        "<span style='color:blue'>1. Augment `H` with ones to create `H_aug`</span><div></div>\n",
        "<span style='color:blue'>2. Combine `w2` and `b2` to create the output weight matric `W2`</span><div></div>\n",
        "<span style='color:blue'>3. Perform the matrix multiplication to produce `Z2`</span><div></div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "LE49hrn_YjhO"
      },
      "outputs": [],
      "source": [
        "### edTest(test_Z2) ###\n",
        "\n",
        "# Add a column of ones to H using the function defined\n",
        "H_aug = add_ones_col(H)\n",
        "\n",
        "# Add biases to weight matrix by stacking\n",
        "W2 = np.vstack((b2, w2))\n",
        "\n",
        "# Compute Z2 based on the equation above\n",
        "Z2 = H_aug @ W2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKcEFJJfYjhO"
      },
      "source": [
        "Finally we use the softmax activation on `Z2`. Now for each observation we have an output vector of length 3 which can be interpreted as a probability (they sum to 1).\n",
        "$$\n",
        "\\textit{a}_{\\text{softmax}}(\\textbf{Z}^2)=\n",
        "\\begin{bmatrix}\n",
        "\\hat{y}_{11} & \\hat{y}_{12} & \\hat{y}_{13}\\\\\n",
        "\\hat{y}_{21} & \\hat{y}_{22} & \\hat{y}_{23}\\\\\n",
        "\\vdots & \\vdots & \\vdots \\\\\n",
        "\\hat{y}_{n1} & \\hat{y}_{n2} & \\hat{y}_{n3}\\\\\n",
        "\\end{bmatrix}\n",
        "= \\hat{\\textbf{Y}}\n",
        "$$\n",
        "\n",
        "<span style='color:blue'>1. Define softmax</span><div></div>\n",
        "<span style='color:blue'>2. Use `softmax` on `Z2` to create `Y_hat`</span><div></div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "H5t-zXV_YjhP"
      },
      "outputs": [],
      "source": [
        "def softmax(z):\n",
        "\n",
        "    '''\n",
        "    Input: z - 2D numpy array of logits \n",
        "           rows are observations, classes are columns \n",
        "    Returns: y_hat - 2D numpy array of probabilities\n",
        "             rows are observations, classes are columns \n",
        "    '''\n",
        "    exp_z = np.exp(z)\n",
        "    sum_exp_z = np.sum(exp_z, axis=1, keepdims=True)\n",
        "\n",
        "    # Hint: we are summing across the columns\n",
        "    # Ensure you maintain the same dimension as the input\n",
        "    y_hat = exp_z / sum_exp_z\n",
        "    \n",
        "    return y_hat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "7CqC131zYjhP"
      },
      "outputs": [],
      "source": [
        "### edTest(test_softmax) ###\n",
        "\n",
        "# Call the defined softmax function to get Y_hat\n",
        "Y_hat = softmax(Z2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNqU0DkcYjhP",
        "outputId": "860ffa39-7fdf-4f24-8c0e-d7cd4d9e7631"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 96.67%\n"
          ]
        }
      ],
      "source": [
        "### edTest(test_acc) ###\n",
        "\n",
        "# From the softmax output, get the predicted y\n",
        "y_hat = np.argmax(Y_hat, axis=1)\n",
        "\n",
        "# Compute the accuracy of your prediction\n",
        "acc = np.mean(y == y_hat)\n",
        "print(f'accuracy: {acc:.2%}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vqCkrLEodWV3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}