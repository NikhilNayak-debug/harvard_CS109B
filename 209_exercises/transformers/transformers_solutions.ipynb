{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2,
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import necessary libraries\n",
                "import time\n",
                "import string\n",
                "import re\n",
                "import random\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "import tensorflow as tf\n",
                "from tensorflow.python.keras import backend as K\n",
                "\n",
                "AUTOTUNE = tf.data.experimental.AUTOTUNE"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Read the English to Spanish datafile into a pandas dataframe\n",
                "# Use columns [0,1] with tab as the seperator, no head\n",
                "# Set the names of the columns as \"English\" and \"Spanish\"\n",
                "data = pd.read_csv('spa.txt', sep='\\t', header=None, usecols=[0,1], names=['English', 'Spanish'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "\u003cdiv\u003e\n\u003cstyle scoped\u003e\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\u003c/style\u003e\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\n  \u003cthead\u003e\n    \u003ctr style=\"text-align: right;\"\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003eEnglish\u003c/th\u003e\n      \u003cth\u003eSpanish\u003c/th\u003e\n    \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003cth\u003e0\u003c/th\u003e\n      \u003ctd\u003eGo.\u003c/td\u003e\n      \u003ctd\u003eVe.\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e1\u003c/th\u003e\n      \u003ctd\u003eGo.\u003c/td\u003e\n      \u003ctd\u003eVete.\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e2\u003c/th\u003e\n      \u003ctd\u003eGo.\u003c/td\u003e\n      \u003ctd\u003eVaya.\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e3\u003c/th\u003e\n      \u003ctd\u003eGo.\u003c/td\u003e\n      \u003ctd\u003eVáyase.\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e4\u003c/th\u003e\n      \u003ctd\u003eHi.\u003c/td\u003e\n      \u003ctd\u003eHola.\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003c/div\u003e",
                        "text/plain": "  English  Spanish\n0     Go.      Ve.\n1     Go.    Vete.\n2     Go.    Vaya.\n3     Go.  Váyase.\n4     Hi.    Hola."
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Take a quick look at the dataframe\n",
                "data.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Shape: (10000, 2)\n"
                }
            ],
            "source": [
                "# Subset data to just the first 10000 rows so that we train on Ed\n",
                "data = data[:10000]\n",
                "print(\"Shape:\",data.shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": [
                "# For each English and Spanish sentence in the dataframe \n",
                "# add the start \u003cs\u003e and end \u003c/s\u003e tokens\n",
                "data.Spanish = '\u003cs\u003e '+data.Spanish+' \u003c/s\u003e'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2022-03-31 22:52:09.645091: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-03-31 22:52:09.645391: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
                }
            ],
            "source": [
                "vocab_size = 5000\n",
                "sequence_length = 8 #20\n",
                "\n",
                "# Build a function to clean spanish text\n",
                "# Convert to lower case\n",
                "# filter out the special spanish token ¡ and ¿ commonly used in formal spanish\n",
                "strip_chars = '!\"#$%\u0026\\'()*+,-.:;=?@[\\]^_`{|}~¿¡'\n",
                "def standardize_text(input_string):\n",
                "    lowercase = tf.strings.lower(input_string)\n",
                "    return tf.strings.regex_replace(\n",
                "        lowercase, f\"[{re.escape(strip_chars)}]\", \"\")\n",
                "\n",
                "# Create a vectorization object for Spanish\n",
                "vectorization_spa = tf.keras.layers.TextVectorization(\n",
                "    max_tokens=vocab_size,\n",
                "    output_mode=\"int\",\n",
                "    output_sequence_length=sequence_length + 1,\n",
                "    standardize=standardize_text,\n",
                ")\n",
                "\n",
                "# Create a vectorization object for English\n",
                "vectorization_eng = tf.keras.layers.TextVectorization(\n",
                "    max_tokens=vocab_size,\n",
                "    output_mode=\"int\",\n",
                "    output_sequence_length=sequence_length,\n",
                ")\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Fit both vectorizations on all the text in the dataframe for each language \n",
                "vectorization_eng.adapt(data.English)\n",
                "vectorization_spa.adapt(data.Spanish)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "train_data \u003cPrefetchDataset element_spec=((TensorSpec(shape=(None, 8), dtype=tf.int64, name=None), TensorSpec(shape=(None, 8), dtype=tf.int64, name=None)), TensorSpec(shape=(None, 8), dtype=tf.int64, name=None))\u003e\n"
                }
            ],
            "source": [
                "# Build Data Pipelines using TF Dataset\n",
                "\n",
                "# Set batch size to 256 and train shuffle buffer size to 5000\n",
                "batch_size = 256\n",
                "train_shuffle_buffer_size = 5000\n",
                "\n",
                "# Write a mapping function to process the input data\n",
                "# First vectorize both english and spanish.\n",
                "# Since we are using the decoder to predict the next word, the target language must be processed. \n",
                "# The source data and target must be shifted by one position\n",
                "def process(eng, spa):\n",
                "    eng = vectorization_eng(eng)\n",
                "    spa = vectorization_spa(spa)\n",
                "    return (eng,spa[:, :-1]), spa[:, 1:]\n",
                "\n",
                "# Create TF Dataset, pass in english and spanish as x,y\n",
                "train_data = tf.data.Dataset.from_tensor_slices((data.English, data.Spanish))\n",
                "\n",
                "#############\n",
                "# Train data\n",
                "#############\n",
                "# Apply all data processing logic\n",
                "train_data = train_data.shuffle(buffer_size=train_shuffle_buffer_size)\n",
                "train_data = train_data.batch(batch_size)\n",
                "train_data = train_data.map(process, num_parallel_calls=AUTOTUNE)\n",
                "train_data = train_data.prefetch(AUTOTUNE)\n",
                "\n",
                "print(\"train_data\",train_data)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Positional Encoding**\n",
                "\n",
                "\u003cimg src=\"https://storage.googleapis.com/public_colab_images/nlp/positional_encoding.png\" width=\"350\"\u003e"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Write a function to generate positional encodings\n",
                "\n",
                "def generate_positional_encoding(max_length, model_size):\n",
                "    pos_enc = np.array(\n",
                "        [\n",
                "            [pos / np.power(10000, 2 * (j // 2) / model_size) for j in range(model_size)]\n",
                "            if pos != 0\n",
                "            else np.zeros(model_size)\n",
                "            for pos in range(max_length)\n",
                "        ]\n",
                "    )\n",
                "    pos_enc[1:, 0::2] = np.sin(pos_enc[1:, 0::2])  # dim 2i\n",
                "    pos_enc[1:, 1::2] = np.cos(pos_enc[1:, 1::2])  # dim 2i+1\n",
                "    return pos_enc"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "(60, 256)\n"
                }
            ],
            "source": [
                "# Generate postional encodings for sequence length of 60 and embedding dimension of 256\n",
                "positional_encodings = generate_positional_encoding(60, 256)\n",
                "print(positional_encodings.shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compute the dot product of postion 1 with every other postions\n",
                "dot_results = []\n",
                "for idx in range(positional_encodings.shape[0]):\n",
                "  dot_results.append(np.dot(positional_encodings[1], positional_encodings[idx]))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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\n",
                        "text/plain": "\u003cFigure size 1440x360 with 1 Axes\u003e"
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Plot the dot product results\n",
                "fig = plt.figure(figsize=(20,5))\n",
                "axs = fig.add_subplot(1,3,1)\n",
                "axs.plot(np.arange(0, positional_encodings.shape[0]), dot_results)\n",
                "axs.set_xlabel('Positions')\n",
                "axs.set_ylabel('Dot product of positions')\n",
                "plt.show()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ⏸ Why do we need to implement positional encoding?\n",
                "#### A. The transformer encoder needs a way to map token postions to the decoder \n",
                "#### B. Positional encoding helps the token embedding add context to them\n",
                "#### C. A transformer reads in the entire input sequence at once and therefore is order agnositic\n",
                "#### D. Positional encoding adds noise to input sequence to make back propagation more stable"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_chow1) ###\n",
                "# Submit an answer choice as a string below (eg. if you choose option A, put 'A')\n",
                "answer1 = 'C'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create a Positional Embedding layer that combines\n",
                "# token embedding with positional encoding\n",
                "class PositionalEmbedding(tf.keras.layers.Layer):\n",
                "    def __init__(self, sequence_length, input_dim, output_dim):\n",
                "      super().__init__()\n",
                "\n",
                "      # Layer parameters\n",
                "      self.sequence_length = sequence_length\n",
                "      self.input_dim = input_dim\n",
                "      self.output_dim = output_dim\n",
                "\n",
                "      # Token embedding Layer\n",
                "      self.token_embeddings = tf.keras.layers.Embedding(input_dim=input_dim, output_dim=output_dim)\n",
                "\n",
                "    def call(self, inputs):\n",
                "      # Generate token embeddings\n",
                "      embedded_tokens = self.token_embeddings(inputs)\n",
                "      # Add positional encoding to tge token embedding\n",
                "      return embedded_tokens + generate_positional_encoding(self.sequence_length,self.output_dim)\n",
                "\n",
                "    def compute_mask(self, inputs, mask=None):\n",
                "        return tf.math.not_equal(inputs, 0)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Transformer Encoder**\n",
                "\n",
                "\u003cimg src=\"https://storage.googleapis.com/public_colab_images/nlp/transformer_encoder.png\" height=\"300\"\u003e"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create the Transformer Encoder\n",
                "class Encoder(tf.keras.layers.Layer):\n",
                "    def __init__(self, embed_dim, dense_dim, num_heads):\n",
                "        super().__init__()\n",
                "        # Layer parameters\n",
                "        self.embed_dim = embed_dim\n",
                "        self.dense_dim = dense_dim\n",
                "        self.num_heads = num_heads\n",
                "\n",
                "        # MultiHeadAttention Layer - Self Attention\n",
                "        self.attention = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
                "        # Normalization Layer\n",
                "        self.attention_norm = tf.keras.layers.LayerNormalization()\n",
                "\n",
                "        # Dense projection\n",
                "        self.dense_proj = tf.keras.Sequential(\n",
                "            [tf.keras.layers.Dense(units=dense_dim, activation=\"relu\"),\n",
                "             tf.keras.layers.Dense(units=embed_dim)]\n",
                "        )\n",
                "        # Normalization Layer\n",
                "        self.dense_projection_norm = tf.keras.layers.LayerNormalization()\n",
                "\n",
                "    def call(self, inputs, mask=None):\n",
                "        # Apply mask\n",
                "        if mask is not None:\n",
                "            mask = mask[:, tf.newaxis, :]\n",
                "        \n",
                "        # Compute Self Attention\n",
                "        self_attention = self.attention(query=inputs, value=inputs, key=inputs, attention_mask=mask)\n",
                "        # Apply Normalization + Residual connection\n",
                "        self_attention = self.attention_norm(inputs + self_attention)\n",
                "\n",
                "        # Apply projection\n",
                "        layer_output = self.dense_proj(self_attention)\n",
                "        # Apply Normalization + Residual connection\n",
                "        layer_output = self.dense_projection_norm(self_attention + layer_output)\n",
                "        return layer_output"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ⏸ Query, Key, Value in a Multi Head Attention layer are used for:\n",
                "#### A. Lookup tables to find contextual mappings between words\n",
                "#### B. Training weights\n",
                "#### C. Transformation functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_chow2) ###\n",
                "# Submit an answer choice as a string below (eg. if you choose option A, put 'A')\n",
                "answer2 = 'B'"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Transformer Decoder**\n",
                "\n",
                "\u003cimg src=\"https://storage.googleapis.com/public_colab_images/nlp/transformer_decoder.png\" height=\"400\"\u003e"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create the Transformer decoder\n",
                "class Decoder(tf.keras.layers.Layer):\n",
                "    def __init__(self, embed_dim, dense_dim, num_heads):\n",
                "        super().__init__()\n",
                "        # Layer parameters\n",
                "        self.embed_dim = embed_dim\n",
                "        self.dense_dim = dense_dim\n",
                "        self.num_heads = num_heads\n",
                "\n",
                "        # MultiHeadAttention Layer - Self Attention\n",
                "        self.attention_1 = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
                "        # Normalization Layer\n",
                "        self.attention_1_norm = tf.keras.layers.LayerNormalization()\n",
                "\n",
                "        # MultiHeadAttention Layer - Encoder-Decoder Attention\n",
                "        self.attention_2 = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
                "        # Normalization Layer\n",
                "        self.attention_2_norm = tf.keras.layers.LayerNormalization()\n",
                "\n",
                "        # Dense projection\n",
                "        self.dense_proj = tf.keras.Sequential(\n",
                "            [tf.keras.layers.Dense(units=dense_dim, activation=\"relu\"),\n",
                "             tf.keras.layers.Dense(units=embed_dim)]\n",
                "        )\n",
                "        # Normalization Layer\n",
                "        self.dense_projection_norm = tf.keras.layers.LayerNormalization()\n",
                "\n",
                "        # Set supports_masking to ensures that the layer will propagate its input mask to its outputs\n",
                "        self.supports_masking = True\n",
                "\n",
                "    def get_causal_attention_mask(self, inputs):\n",
                "        \"\"\"\n",
                "        Method that generates a causal mask:\n",
                "        Since the decoder looks at the entire sequence at once, we need to mask the future\n",
                "        \"\"\"\n",
                "        input_shape = tf.shape(inputs)\n",
                "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
                "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
                "        j = tf.range(sequence_length)\n",
                "        mask = tf.cast(i \u003e= j, dtype=\"int32\")\n",
                "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
                "        mult = tf.concat(\n",
                "            [tf.expand_dims(batch_size, -1),\n",
                "             tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
                "        return tf.tile(mask, mult)\n",
                "\n",
                "    def call(self, inputs, encoder_outputs, mask=None):\n",
                "        # Get Causal Attention Mask\n",
                "        causal_mask = self.get_causal_attention_mask(inputs)\n",
                "        # Apply Padding Masks\n",
                "        if mask is not None:\n",
                "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
                "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
                "        \n",
                "        # Compute Self Attention\n",
                "        self_attention = self.attention_1(query=inputs,\n",
                "                                              value=inputs,\n",
                "                                              key=inputs,attention_mask=causal_mask)\n",
                "        # Apply Normalization + Residual connection\n",
                "        self_attention = self.attention_1_norm(inputs + self_attention)\n",
                "\n",
                "        # Compute Encoder-Decoder Attention\n",
                "        encoder_decoder_attention = self.attention_2(query=self_attention,\n",
                "                                              value=encoder_outputs,\n",
                "                                              key=encoder_outputs,attention_mask=padding_mask)\n",
                "        # Apply Normalization + Residual connection\n",
                "        encoder_decoder_attention = self.attention_2_norm(self_attention + encoder_decoder_attention)\n",
                "\n",
                "        # Apply projection\n",
                "        layer_output = self.dense_proj(encoder_decoder_attention)\n",
                "        # Apply Normalization + Residual connection\n",
                "        layer_output = self.dense_projection_norm(encoder_decoder_attention + layer_output)\n",
                "        return layer_output"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ⏸ The second Multi Head Attention layer in the decoder (attention_2):\n",
                "#### A. Computes the attention score on the decoder inputs with respect to the encoder outputs \n",
                "#### B. Computes the self attention scores for the decoder inputs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_chow3) ###\n",
                "# Submit an answer choice as a string below (eg. if you choose option A, put 'A')\n",
                "answer3 = 'A'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": [
                "############################\n",
                "# Training Params\n",
                "############################\n",
                "learning_rate = 0.001\n",
                "epochs = 20\n",
                "embedding_dim = 128\n",
                "dense_dim = 512\n",
                "num_heads = 4\n",
                "\n",
                "# Free up memory\n",
                "tf.keras.backend.clear_session()\n",
                "\n",
                "# Build the model\n",
                "# Model input\n",
                "inputs_eng = tf.keras.Input(shape=[None])\n",
                "inputs_spa = tf.keras.Input(shape=[None])\n",
                "\n",
                "# Build the Encoder\n",
                "encoder_ip = PositionalEmbedding(sequence_length, vocab_size, embedding_dim)(inputs_eng)\n",
                "encoder_op = Encoder(embedding_dim, dense_dim, num_heads)(encoder_ip)\n",
                "\n",
                "# Build the Decoder\n",
                "decoder_ip = PositionalEmbedding(sequence_length, vocab_size, embedding_dim)(inputs_spa)\n",
                "decoder_op = Decoder(embedding_dim, dense_dim, num_heads)(decoder_ip, encoder_op)\n",
                "decoder_op = tf.keras.layers.Dropout(0.5)(decoder_op)\n",
                "\n",
                "# Output Layer\n",
                "output = tf.keras.layers.Dense(units=vocab_size, activation=\"softmax\")(decoder_op)\n",
                "\n",
                "# Create model\n",
                "model = tf.keras.Model([inputs_eng, inputs_spa], output)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_1 (InputLayer)           [(None, None)]       0           []                               \n                                                                                                  \n input_2 (InputLayer)           [(None, None)]       0           []                               \n                                                                                                  \n positional_embedding (Position  (None, 8, 128)      640000      ['input_1[0][0]']                \n alEmbedding)                                                                                     \n                                                                                                  \n positional_embedding_1 (Positi  (None, 8, 128)      640000      ['input_2[0][0]']                \n onalEmbedding)                                                                                   \n                                                                                                  \n encoder (Encoder)              (None, 8, 128)       396032      ['positional_embedding[0][0]']   \n                                                                                                  \n decoder (Decoder)              (None, 8, 128)       660096      ['positional_embedding_1[0][0]', \n                                                                  'encoder[0][0]']                \n                                                                                                  \n dropout (Dropout)              (None, 8, 128)       0           ['decoder[0][0]']                \n                                                                                                  \n dense_4 (Dense)                (None, 8, 5000)      645000      ['dropout[0][0]']                \n                                                                                                  \n==================================================================================================\nTotal params: 2,981,128\nTrainable params: 2,981,128\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\n"
                }
            ],
            "source": [
                "# Print the model architecture\n",
                "print(model.summary())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Training execution time (mins) 6.545935074488322\n"
                }
            ],
            "source": [
                "# Optimizer\n",
                "optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
                "# Loss\n",
                "loss = tf.keras.losses.sparse_categorical_crossentropy\n",
                "\n",
                "# Compile\n",
                "model.compile(loss=loss,optimizer=optimizer)\n",
                "\n",
                "# Train model\n",
                "start_time = time.time()\n",
                "print(\"Training...\")\n",
                "training_results = model.fit(\n",
                "        train_data,\n",
                "        epochs=epochs, \n",
                "        verbose=0)\n",
                "execution_time = (time.time() - start_time)/60.0\n",
                "print(\"Training execution time (mins)\",execution_time)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "-\nTom drowned.\n\u003cs\u003e tomás      a \n-\nI'm not married.\n\u003cs\u003e no está libre     \n-\nI'm weak.\n\u003cs\u003e estoy borracho      \n-\nTom is tidy.\n\u003cs\u003e no está en el dinero   \n-\nYou can do it.\n\u003cs\u003e que hacerlo      \n-\nCan I help you?\n\u003cs\u003e que te conocen     \n-\nI drank a lot.\n\u003cs\u003e una vez      \n-\nLet Tom come.\n\u003cs\u003e a tom      a\n-\nTom is useless.\n\u003cs\u003e está tu un ángel    \n-\nThis is OK.\n\u003cs\u003e está bien      \n"
                }
            ],
            "source": [
                "spa_vocab = vectorization_spa.get_vocabulary()\n",
                "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
                "max_decoded_sentence_length = sequence_length\n",
                "\n",
                "def decode_sequence(input_sentence):\n",
                "    tokenized_input_sentence = vectorization_eng([input_sentence])\n",
                "    decoded_sentence = \"\u003cs\u003e\"\n",
                "    for i in range(max_decoded_sentence_length):\n",
                "        tokenized_target_sentence = vectorization_spa(\n",
                "            [decoded_sentence])[:, :-1]\n",
                "        predictions = model(\n",
                "            [tokenized_input_sentence, tokenized_target_sentence])\n",
                "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
                "        sampled_token = spa_index_lookup[sampled_token_index]\n",
                "        decoded_sentence += \" \" + sampled_token\n",
                "        if sampled_token == \"\u003c/s\u003e\":\n",
                "            break\n",
                "    return decoded_sentence\n",
                "\n",
                "for _ in range(10):\n",
                "    input_sentence = random.choice(data.English)\n",
                "    print(\"-\")\n",
                "    print(input_sentence)\n",
                "    print(decode_sequence(input_sentence))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                ""
            ]
        }
    ]
}
